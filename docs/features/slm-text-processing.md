# SLMテキスト処理（校正・要約）

**カテゴリ**: 高度な機能 | **優先度**: 任意

ローカルで動作するSLM（Small Language Model）を使用して、文字起こし結果の校正・要約を行う機能。

---

## 目的

- 文字起こし結果の誤字脱字修正、句読点追加などの校正
- 長文の要約生成
- オフライン環境での動作（プライバシー重視）

---

## モデル管理

Whisperモデルと同様の方式を採用する。

### モデル候補（軽量・日本語対応）

| モデル | サイズ | 説明 |
|--------|--------|------|
| Phi-3 Mini | ~2GB | Microsoft製、多言語対応 |
| Gemma 2 2B | ~1.5GB | Google製、軽量 |
| Qwen2 1.5B | ~1GB | Alibaba製、日本語対応 |

**注**: 最終的なモデル選定は実装時に検証して決定。GGUF形式を使用。

### ダウンロード設定

- デフォルトURL: HuggingFaceまたは公式リポジトリ
- カスタムURL対応（社内ホスティング用）
- Whisperモデルと同様の設定方式

### モデルライフサイクル

| 操作 | 説明 |
|------|------|
| ダウンロード | 選択したモデルを取得 |
| 一覧表示 | ダウンロード済みモデルを表示 |
| 削除 | 不要なモデルを削除 |
| 切り替え | 使用するモデルを選択 |

---

## 機能

### 1. 校正機能

- 誤字脱字の修正
- 句読点の追加・修正
- 表記ゆれの統一
- 元テキストとの差分表示

### 2. 要約機能

- 文字起こし結果の要約生成
- 要約の長さ指定（短/中/長）
- 箇条書き形式オプション

---

## テスト要件

### TypeScript (Vitest)

| テスト | 内容 |
|--------|------|
| プロンプト生成 | 校正用プロンプトが正しく生成される |
| プロンプト生成 | 要約用プロンプトが正しく生成される |
| 結果パース | SLM出力から結果を正しく抽出 |

### Rust (cargo test)

| テスト | 内容 |
|--------|------|
| モデル一覧 | 利用可能なモデル一覧を返す |
| モデルパス | モデルファイルパスを正しく解決 |
| ダウンロードURL | カスタムURL設定が反映される |

---

## 実装内容

### Backend (Rust)

1. **SLMモジュール** (`src-tauri/src/slm/`)
   - llama-cpp-rs（llama.cppバインディング）の統合
   - モデル管理（ダウンロード、削除、一覧）
   - 推論実行

2. **Tauriコマンド**
   - `slm:list_models` - 利用可能なモデル一覧
   - `slm:download_model` - モデルダウンロード
   - `slm:delete_model` - モデル削除
   - `slm:proofread` - 校正実行
   - `slm:summarize` - 要約実行

3. **IPCイベント**
   - `slm:download-progress` - ダウンロード進捗
   - `slm:inference-progress` - 推論進捗

### Frontend (TypeScript)

1. **型定義** (`src/types/slm.ts`)
   - SlmModel, SlmConfig, ProofreadResult, SummaryResult

2. **Primitives** (`src/primitives/createSlm.ts`)
   - モデル管理状態
   - 校正・要約の実行と結果管理

3. **UIコンポーネント**
   - SlmModelManager - モデルのダウンロード・削除UI
   - ProofreadPanel - 校正結果表示・差分ビュー
   - SummaryPanel - 要約結果表示

---

## UI設計

### 結果画面への統合

文字起こし結果画面にタブまたはボタンで切り替え：

- **原文** - 文字起こし結果そのまま
- **校正** - 校正済みテキスト（差分ハイライト）
- **要約** - 要約テキスト

### 設定画面

- 使用モデルの選択
- モデルダウンロード/削除
- ダウンロードURL設定
- 要約の長さ設定

---

## 依存関係

### Rust crates

| Crate | 用途 |
|-------|------|
| llama-cpp-rs または llama-cpp-2 | llama.cppバインディング |

### 既存機能との連携

- Whisperモデル管理と同様のUI/UXパターンを踏襲
- 設定永続化（tauri-plugin-store）を使用

---

## 作成ファイル

| ファイル | 説明 |
|----------|------|
| `src-tauri/src/slm/` | SLMモジュール（Rust） |
| `src/types/slm.ts` | 型定義 |
| `src/primitives/createSlm.ts` | SolidJS Primitive |
| `src/components/slm/` | UIコンポーネント |

---

## 完了条件

- [ ] モデルをダウンロードできる
- [ ] ダウンロード済みモデルを一覧表示できる
- [ ] モデルを削除できる
- [ ] カスタムダウンロードURLを設定できる
- [ ] 校正機能が動作する
- [ ] 要約機能が動作する
- [ ] `pnpm test` で全テストが通る
- [ ] `cargo test` で全テストが通る

---

## 実装上の注意

- llama.cppのビルドにはCMakeが必要（ビルド手順をドキュメント化）
- GPU対応はオプション（初期実装はCPUのみでも可）
- メモリ使用量に注意（2GB以下のモデルを推奨）
